{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docplex\n",
    "from docplex.mp.model import Model\n",
    "from docplex.mp.progress import *\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def DataPreperation(datasetname,sampleAmount, featCART, seed):\n",
    "    global numericalGroup\n",
    "    numericalGroup = []\n",
    "    global data\n",
    "    global trainData\n",
    "    global samplePos\n",
    "    global trainDataDummies\n",
    "    global groupsOfFeatures\n",
    "    global featureToGroup\n",
    "    global testData\n",
    "    global testDataDummies\n",
    "    global samplePosTest\n",
    "    # Read in prefered dataset\n",
    "    if(datasetname == 'chess'):\n",
    "        dataChess = pd.read_csv(\"kr-vs-kp.data\")\n",
    "        data = dataChess.dropna().sample(n=sampleAmount, random_state=1)\n",
    "        trainData = data.drop(columns=['won'])\n",
    "        samplePos = (data['won'] == 'won')*1\n",
    "    elif(datasetname == 'adult'):\n",
    "        dataAdult = pd.read_csv(\"a1a.txt\", delim_whitespace=True, header=None) \n",
    "        for i in range(1, 15):\n",
    "            dataAdult[i] = dataAdult[i].str.replace(':1', '', regex=True)\n",
    "        data = dataAdult.dropna() #.sample(n=sampleAmount, random_state=1)\n",
    "        data, testData = train_test_split(data, train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        samplePos = (data[0] == 1)*1\n",
    "        trainData = data.drop(columns=0)\n",
    "        \n",
    "        samplePosTest = (testData[0] == 1)*1\n",
    "        testData = testData.drop(columns=0)\n",
    "        \n",
    "        #numericalGroup = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "    elif(datasetname == 'breast'):\n",
    "        dataBreast = pd.read_csv(\"breast.txt\", delim_whitespace=True, header=0, names=['Class','Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses'])\n",
    "        dataBreast = dataBreast.drop(columns='Sample code number') #drop id-numbers of observations\n",
    "        if featCART:\n",
    "            dataBreast = dataBreast[['Class', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Bare Nuclei']]\n",
    "        data = dataBreast.sample(n=sampleAmount, random_state=1)\n",
    "        trainData = data.drop(columns='Class')\n",
    "        for i in trainData.columns: #take away the rownumber: of all variables.\n",
    "                trainData[i] = trainData[i].str[trainData.iloc[0][i].index(':')+1:]\n",
    "        samplePos = (data['Class'] == 2)*1\n",
    "        numericalGroup = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "      \n",
    "    elif(datasetname == 'mushroom'):\n",
    "        dataMushroom = pd.read_csv(\"agaricus-lepiota.data\", header=0, names=['edible','cap-shape','cap-surface','cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "        dataMushroom = dataMushroom.replace(\"?\", np.nan)\n",
    "        data = dataMushroom.dropna()#.sample(n=sampleAmount, random_state=1)\n",
    "        data, testData = train_test_split(data, train_size=600,random_state=seed)\n",
    "\n",
    "        #data = dataMushroom.dropna().sample(n=5, random_state=1).drop(columns=['cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "        \n",
    "        trainData = data.drop(columns='edible')\n",
    "        samplePos = (data['edible'] == 'e')*1\n",
    "        \n",
    "        samplePosTest = (testData['edible'] == 'e')*1\n",
    "        testData = testData.drop(columns='edible')\n",
    "    elif(datasetname == 'tictactoe'):\n",
    "        dataTicTac = pd.read_csv(\"tic-tac-toe.data\", header=None)\n",
    "        data = dataTicTac.dropna().sample(n=sampleAmount, random_state=1)\n",
    "        trainData = data.drop(columns=9)\n",
    "        samplePos = (data[9] == 'positive')*1\n",
    "    elif(datasetname == 'monks'):\n",
    "        dataMonks = pd.read_csv(\"monks-1.test\", delim_whitespace=True, header = None)\n",
    "        data = dataMonks.sample(n=sampleAmount, random_state=1)\n",
    "        for i in data.columns:\n",
    "            data[i] = data[i].apply(str)\n",
    "        trainData = data.drop(columns=[0, 7])\n",
    "        samplePos = (data[0] == '1')*1\n",
    "    elif(datasetname == 'votes'):\n",
    "        dataVotes = pd.read_csv(\"house-votes-84.data\", header=None)\n",
    "        dataVotes = dataVotes.replace(\"?\", np.nan)\n",
    "        data = dataVotes.dropna().sample(n=sampleAmount, random_state=1)\n",
    "        trainData = data.drop(columns=0)\n",
    "        samplePos = (data[0] == 'democrat')*1\n",
    "    elif(datasetname == 'heart'):\n",
    "        dataHeart1 = pd.read_csv(\"SPECT.test\", header=None)\n",
    "        dataHeart2 = pd.read_csv(\"SPECT.train\", header=None)\n",
    "        frames = [dataHeart1, dataHeart2]\n",
    "        dataHeart = pd.concat(frames)\n",
    "        data = dataHeart.dropna().sample(n=sampleAmount, random_state=1)\n",
    "        for i in data.columns:\n",
    "            data[i] = data[i].apply(str)\n",
    "        trainData = data.drop(columns=0)\n",
    "        samplePos = (data[0] == '1')*1\n",
    "    elif(datasetname == 'student'):\n",
    "        studentMat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "        studentPor = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "        studentall = pd.merge(studentMat, studentPor, on=[\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])\n",
    "        numericalGroup = [31, 30, 29, 28, 3]\n",
    "    else:\n",
    "        raise ValueError('The dataset was not recognised.')\n",
    "\n",
    "    #process data for tree\n",
    "\n",
    "    start = 0\n",
    "    for i in trainData.columns:\n",
    "        if (start == 0):\n",
    "            trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "            trainDataDummies = trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "            start = 1\n",
    "        else:\n",
    "            trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "            trainDataDummies = trainDataDummies.join(trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "    \n",
    "    start = 0\n",
    "    for i in testData.columns:\n",
    "        if (start == 0):\n",
    "            testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "            testDataDummies = testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "            start = 1\n",
    "        else:\n",
    "            testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "            testDataDummies = testDataDummies.join(testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "\n",
    "    \n",
    "    groupsN = trainData.shape[1]\n",
    "    G = range(1, groupsN + 1)\n",
    "    groupsOfFeatures = trainData.nunique()\n",
    "    featureToGroup = []\n",
    "    for g in G:\n",
    "        amountOfFeatures = groupsOfFeatures.iloc[g-1]\n",
    "        for f in range(amountOfFeatures):\n",
    "            featureToGroup.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity):\n",
    "    model = Model(\"tree\")\n",
    "    model.parameters.randomseed = 42\n",
    "    \n",
    "    #datashape\n",
    "    N = trainData.shape[0] # amount of samples\n",
    "    I = range(1, N + 1) # all samples\n",
    "    groupsN = trainData.shape[1] # amount of groupes\n",
    "    groupsOfFeatures = trainData.nunique() # amount of features per group\n",
    "    G = range(1, groupsN + 1) #groups\n",
    "    J = range(1, groupsOfFeatures.sum() + 1) #features\n",
    "    Iplus = np.where(samplePos == 1)[0]\n",
    "    Iplus = [x+1 for x in Iplus]\n",
    "    Imin = np.where(samplePos == 0)[0]\n",
    "    Imin = [x+1 for x in Imin]\n",
    "    \n",
    "    \n",
    "    #tree topology\n",
    "    if (typeOfTree == 1):\n",
    "        #simple tree of depth 2\n",
    "        dNodesN = 3\n",
    "        lNodesN = 4\n",
    "        Bplus = [1, 3]\n",
    "        Bmin = [2, 4]\n",
    "        route = np.array([[1, 1, 0], [1, -1, 0], [-1, 0, 1], [-1, 0, -1]])\n",
    "        nonAdjLeaf = [1]\n",
    "        nonAdjLeafSymm = [1]\n",
    "        AdjLeaf = [2, 3]\n",
    "    if(typeOfTree == 2):\n",
    "        #binary tree with depth 2,5\n",
    "        dNodesN = 5\n",
    "        lNodesN = 6\n",
    "        Bplus = [1, 3, 5]\n",
    "        Bmin = [2, 4, 6]\n",
    "        route = np.array([[1, 1, 1, 0, 0], [1, 1, -1, 0, 0], [1, -1, 0, 1, 0], \\\n",
    "                          [1, -1, 0, -1, 0], [-1, 0, 0, 0, 1],  [-1, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2]\n",
    "        nonAdjLeafSymm = [2]\n",
    "        AdjLeaf = [3, 4, 5]\n",
    "    if(typeOfTree == 3):\n",
    "        #binary tree with depth 3\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 0, 0, 0, 0], [1, 1, -1, 0, 0, 0, 0], [1, -1, 0, 1, 0, 0, 0], \\\n",
    "                         [1, -1, 0, -1, 0, 0, 0], [-1, 0, 0, 0, 1, 1, 0], [-1, 0, 0, 0, 1, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, -1, 0, 1], [-1, 0, 0, 0, -1, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 5]\n",
    "        nonAdjLeafSymm = [1, 2, 5]\n",
    "        AdjLeaf = [3, 4, 6, 7]\n",
    "    if(typeOfTree == 4):\n",
    "        #binary tree with depth 3,5\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 1, 0, 0, 0], [1, 1, 1, -1, 0, 0, 0], [1, 1, -1, 0, 1, 0, 0], \\\n",
    "                         [1, 1, -1, 0, -1, 0, 0], [1, -1, 0, 0, 0, 1, 0], [1, -1, 0, 0, 0, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, 0, 0, 1], [-1, 0, 0, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 3]\n",
    "        nonAdjLeafSymm = [3]\n",
    "        AdjLeaf = [4, 5, 6, 7]\n",
    "        \n",
    "    #make nodes\n",
    "    K = range(1, dNodesN + 1) #decision nodes\n",
    "    B = range(1, lNodesN + 1) #leaf nodes\n",
    "\n",
    "    # --- decision variables --- \n",
    "    idv = [(g, k) for g in G for k in K]\n",
    "    if(relax): \n",
    "        v = model.continuous_var_dict(keys=idv, lb=0, ub=1, name=\"V\") #relaxation of variables of paragraph 4.3.4\n",
    "    else:\n",
    "        v = model.binary_var_dict(keys=idv, name=\"V\")\n",
    "    idz = [(j,k) for j in J for k in K]\n",
    "    if(relax):\n",
    "        idzAdjLeaf = [(j,k) for j in J for k in AdjLeaf]\n",
    "        idzNonAdjLeaf = [(j,k) for j in J for k in nonAdjLeaf]\n",
    "        z = model.continuous_var_dict(keys=idzAdjLeaf, lb=0, ub=1, name=\"Z\")\n",
    "        zNonAdjLeaf = model.binary_var_dict(keys=idzNonAdjLeaf, name=\"Z\")\n",
    "        z.update(zNonAdjLeaf)\n",
    "    else:\n",
    "        idz = [(j,k) for j in J for k in K]\n",
    "        z = model.binary_var_dict(keys=idz, name=\"Z\")\n",
    "    idc = [(b,i) for b in B for i in I]\n",
    "    if(relax):\n",
    "        c = model.continuous_var_dict(keys=idc,ub=1, name=\"C\")\n",
    "    else:\n",
    "        c = model.binary_var_dict(keys=idc, name=\"C\")\n",
    "    idL = [(i,k) for i in I for k in K]\n",
    "    L = model.binary_var_dict(keys=idL, name=\"L\")\n",
    "    idR = [(i,k) for i in I for k in K]\n",
    "    R = model.binary_var_dict(keys=idL, name=\"R\")\n",
    "    if(numerical):\n",
    "        idw = [(g,k) for k in K for g in numericalGroup]\n",
    "        w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "    if(combCon):\n",
    "        if(numerical):\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            wcomb = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "            w.update(wcomb)\n",
    "        else:\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "\n",
    "    # --- constraints ---\n",
    "    for k in K:\n",
    "        model.add_constraint(model.sum(v[g, k] for g in G) == 1) #constraint (1)\n",
    "\n",
    "    for k in K:\n",
    "        for j in J:\n",
    "            model.add_constraint(z[j,k] <= v[featureToGroup[j-1], k]) #constraint (2)\n",
    "\n",
    "    for k in K:\n",
    "        for i in I:\n",
    "            model.add_constraint(L[i,k] == sum(z[j,k] for j in J if trainDataDummies.iloc[i-1,j-1] == 1)) #constraint (3)\n",
    "            model.add_constraint(R[i,k] == 1 - L[i,k]) #constraint (4)\n",
    "    \n",
    "    if(strength):\n",
    "        for i in I:\n",
    "            for k in K:\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == 1) <= L[i,k]) #constraint (11)\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == -1) <= R[i,k]) #constraint (12)\n",
    "    else:\n",
    "        for b in B:\n",
    "            for i in I:\n",
    "                for k in K:\n",
    "                    switch = route[b-1, k-1]\n",
    "                    if switch == 1:\n",
    "                        model.add_constraint(c[b,i] <= L[i,k]) #constraint (5)\n",
    "                    elif switch == -1:\n",
    "                        model.add_constraint(c[b,i] <= R[i,k]) #constraint (6)\n",
    "        for i in I:\n",
    "            model.add_constraint(model.sum(c[b,i] for b in B) == 1) #constraint (7)\n",
    "    \n",
    "    if(anchor): \n",
    "        for g in G:\n",
    "            for k in nonAdjLeafSymm: #only for nonleafs with symmatrical subtree\n",
    "                model.add_constraint(z[featureToGroup.index(g) + 1, k] == v[g,k]) #constraint (13)\n",
    "                        \n",
    "    if(ExclSameBranchFollowing):\n",
    "        #for k in K:\n",
    "        test=1\n",
    "            #add constraint (9) and (10)\n",
    "            \n",
    "    if(numerical):\n",
    "        #numerical value constraint 4.4\n",
    "        for k in K:\n",
    "            for g in numericalGroup:\n",
    "                featureList = [i for i, x in enumerate(featureToGroup) if x == g]\n",
    "                for j in featureList:\n",
    "                    j = j + 1 #making index start at 1\n",
    "                    if(j-1 == featureList[0]):    \n",
    "                        model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                    elif(j-1 == featureList[-1]):\n",
    "                        model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))\n",
    "                    else:\n",
    "                        model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                        model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))                     \n",
    "                \n",
    "    if(combCon):\n",
    "        for k in K:\n",
    "            for g in G:\n",
    "                if((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard)):\n",
    "                    featureList = [i for i, x in enumerate(featureToGroup) if x == g]\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) <= maxCard + (groupsOfFeatures.iloc[g-1] - maxCard)*(1-w[g,k]))\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) >= (groupsOfFeatures.iloc[g-1] - maxCard) - (groupsOfFeatures.iloc[g-1] - maxCard)*w[g,k])\n",
    "        \n",
    "        \n",
    "    \n",
    "    # --- objective ---\n",
    "    model.objectiveTruePos = model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus)\n",
    "    model.objectiveTrueNeg = model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin)\n",
    "    \n",
    "    if(sensOn):\n",
    "        \n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus) >= math.ceil((1-sensitivity)*len(Iplus) ))\n",
    "        \n",
    "        totalObjective = model.objectiveTrueNeg\n",
    "        \n",
    "        sensitivity\n",
    "    elif(specOn):\n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin) >= math.ceil((1-specificity)*len(Imin) ))\n",
    "\n",
    "        totalObjective = model.objectiveTruePos\n",
    "    else:\n",
    "        totalObjective = model.objectiveTruePos + C*model.objectiveTrueNeg \n",
    "    \n",
    "    model.maximize(totalObjective)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeValidation(solution, testData, trainData):\n",
    "    error = False\n",
    "    currentDecNode = 1\n",
    "    decNodeFeatureDoubleList = []\n",
    "    decNodeFeatureList = []\n",
    "    while(not error):\n",
    "        for feature in range(1, len(trainDataDummies.columns) + 1):\n",
    "            try:\n",
    "                value = sol.get_value('Z_' + str(feature) + '_' + str(currentDecNode))\n",
    "                if(value > 0):\n",
    "                    decNodeFeatureList.append(feature)\n",
    "            except:\n",
    "                error = True\n",
    "                break\n",
    "        if (not error):\n",
    "            currentDecNode = currentDecNode + 1\n",
    "            decNodeFeatureDoubleList.append(decNodeFeatureList)\n",
    "            decNodeFeatureList = []\n",
    "    \n",
    "\n",
    "    dfTest = pd.DataFrame(columns=trainDataDummies.columns)\n",
    "\n",
    "    for col in dfTest.columns:\n",
    "        if col in testData.columns: # copy columns from testdata to dataframe\n",
    "            dfTest[col] = testData[col]\n",
    "    dfTest = dfTest.fillna(0) #works\n",
    "    \n",
    "    #first part done\n",
    "    \n",
    "    #now find good route\n",
    "    LikArray = np.zeros((len(dfTest.index), len(decNodeFeatureDoubleList)))\n",
    "\n",
    "    for i in range(len(dfTest)):\n",
    "        for k in range(len(decNodeFeatureDoubleList)):\n",
    "            #check if Lik equals 1 or 0\n",
    "                if(not k == 2):\n",
    "                    for feature in decNodeFeatureDoubleList[k]:\n",
    "                        if(dfTest.iloc[i,feature-1] == 1):\n",
    "                            LikArray[i,k] = 1\n",
    "    \n",
    "    \n",
    "    totalCorrectClassified = 0\n",
    "    if(typeOfTree == 1):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,3-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "        \n",
    "        \n",
    "    elif(typeOfTree == 3):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(LikArray[i,3-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,4-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,5-1] == 1):\n",
    "                    if(LikArray[i,6-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,7-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                    \n",
    "                \n",
    "    else:\n",
    "        print('error treetype not found...')\n",
    "        \n",
    "    return totalCorrectClassified / samplePosTest.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "Solution for adult with configuration strenght = False anchor = False relax = False\n",
      "6.03099999999904\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c0c1369fadd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0msamplesize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mDataPreperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplesize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mstrength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0manchor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d12e1bf55c90>\u001b[0m in \u001b[0;36mDataPreperation\u001b[1;34m(datasetname, sampleAmount, featCART, seed)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mtestDataDummiesTemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mtestDataDummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestDataDummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDataDummiesTemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestDataDummiesTemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2990\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2992\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3604\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3605\u001b[0m         )\n\u001b[0;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m-> 1397\u001b[1;33m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m         )\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1355\u001b[0m                             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m                             \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m                             \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m                         )\n\u001b[0;32m   1359\u001b[0m                     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1314\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m         )\n\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1720\u001b[0m     )\n\u001b[1;32m-> 1721\u001b[1;33m     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(arr, indexer, out, fill_value)\u001b[0m\n\u001b[0;32m   1507\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m         _take_nd_object(\n\u001b[1;32m-> 1509\u001b[1;33m             \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1510\u001b[0m         )\n\u001b[0;32m   1511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_take_nd_object\u001b[1;34m(arr, indexer, out, axis, fill_value, mask_info)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mneeds_masking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[0moutindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solTime = 60*60*3 #1 hour\n",
    "typeOfTree = 3\n",
    "seed = 1\n",
    "C = 1  #weight to objective function\n",
    "ExclSameBranchFollowing = False #constraint (9) and (10)\n",
    "combCon = False\n",
    "maxCard = 1\n",
    "sensOn = False\n",
    "specOn = False\n",
    "sensitivity = 0.95\n",
    "specificity = 0.95\n",
    "numerical = False\n",
    "\n",
    "trainacc = []\n",
    "testacc = []\n",
    "\n",
    "datasets = [['adult', 200], ['breast', 200], ['chess', 200], ['mushroom', 200], ['tictactoe', 200]]\n",
    "settings = [[False, False, False], [True, False, True], [True, True, False], [False, True, True], [True, True, True]]\n",
    "results = []\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    for setting in settings:\n",
    "        setname = dataset[0]\n",
    "        samplesize = dataset[1]\n",
    "        \n",
    "        DataPreperation(setname, samplesize, False, seed)\n",
    "        strength = setting[0]\n",
    "        anchor = setting[1]\n",
    "        relax = setting[2]\n",
    "        model = decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\n",
    "        model.set_time_limit(solTime)\n",
    "        sol = model.solve()\n",
    "        #gather results\n",
    "        solveTime = model.solve_details.time\n",
    "        nodesProcessed = model.solve_details.nb_nodes_processed\n",
    "        print('Solution for ' + dataset[0] + ' with configuration ' + 'strenght = ' + str(setting[0]) + ' anchor = ' + str(setting[1]) + ' relax = ' + str(setting[2]))\n",
    "        print(solveTime)\n",
    "        print(nodesProcessed)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = [[False, False, False], [True, False, True], [True, True, False], [False, True, True], [True, True, True]]\n",
    "settings[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
