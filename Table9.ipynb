{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docplex\n",
    "from docplex.mp.model import Model\n",
    "from docplex.mp.progress import *\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreperation(datasetname,sampleAmount, featCART, seed):\n",
    "    global numericalGroup\n",
    "    numericalGroup = []\n",
    "    global data\n",
    "    global trainData\n",
    "    global samplePos\n",
    "    global trainDataDummies\n",
    "    global groupsOfFeatures\n",
    "    global featureToGroup\n",
    "    global testData\n",
    "    global testDataDummies\n",
    "    global samplePosTest\n",
    "    # Read in prefered dataset\n",
    "    if(datasetname == 'chess'):\n",
    "        dataChess = pd.read_csv(\"kr-vs-kp.data\", header=0, names=['bkblk','bknwy','bkon8','bkona','bkspr','bkxbq','bkxcr','bkxwp','blxwp','bxqsq','cntxt','dsopp','dwipd','hdchk','katri','mulch','qxmsq','r2ar8','reskd','reskr','rimmx','rkxwp','rxmsq','simpl','skach','skewr','skrxp','spcop','stlmt','thrsk','wkcti','wkna8','wknck','wkovl','wkpos','wtoeg','white_win'])\n",
    "        if featCART:\n",
    "            dataChess = dataChess[['white_win','rimmx','wknck','bxqsq','wkna8', 'wkpos','bkxbq','katri', 'bkblk']]\n",
    "            \n",
    "        dataFirst, testDataFirst = train_test_split(dataChess.dropna(), train_size=0.9, random_state=1)\n",
    "        data, testData = train_test_split(dataFirst, train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns=['white_win'])\n",
    "        samplePos = (data['white_win'] == 'won')*1\n",
    "        samplePosTest = (testData['white_win'] == 'won')*1\n",
    "        testData = testData.drop(columns='white_win')\n",
    "    elif(datasetname == 'adult'):\n",
    "        dataAdult = pd.read_csv(\"a1a.txt\", delim_whitespace=True, header=None, names = ['salery50k','age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country']) \n",
    "        if featCART:\n",
    "            dataAdult = dataAdult[['salery50k','relationship', 'occupation', 'education', 'capital-gain','workclass']]\n",
    "        dataFirst, testDataFirst = train_test_split(dataAdult.dropna(), train_size=0.9, random_state=1)\n",
    "        data, testData = train_test_split(dataFirst, train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns='salery50k')\n",
    "        samplePos = (data['salery50k'] == 1)*1\n",
    "        \n",
    "        samplePosTest = (testData['salery50k'] == 1)*1\n",
    "        testData = testData.drop(columns='salery50k')\n",
    "        \n",
    "        numericalGroup = [1, 3, 5, 11, 12, 13]\n",
    "    elif(datasetname == 'breast'):\n",
    "        dataBreast = pd.read_csv(\"breast.txt\", delim_whitespace=True, header=0, names=['Class','Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses'])\n",
    "        dataBreast = dataBreast.drop(columns='Sample code number') #drop id-numbers of observations\n",
    "        if featCART:\n",
    "            dataBreast = dataBreast[['Class','Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Bare Nuclei']]\n",
    "        dataFirst, testDataFirst = train_test_split(dataBreast.dropna(), train_size=0.9, random_state=1)\n",
    "        data, testData = train_test_split(dataFirst, train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        #for i in trainData.columns: #take away the rownumber: of all variables.\n",
    "        #        trainData[i] = trainData[i].str[trainData.iloc[0][i].index(':')+1:]\n",
    "        samplePos = (data['Class'] == 2)*1\n",
    "        trainData = data.drop(columns='Class')\n",
    "        \n",
    "        samplePosTest = (testData['Class'] == 2)*1\n",
    "        testData = testData.drop(columns='Class')\n",
    "        \n",
    "        numericalGroup = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    elif(datasetname == 'mushroom'):\n",
    "        dataMushroom = pd.read_csv(\"agaricus-lepiota.data\", header=0, names=['edible','cap-shape','cap-surface','cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "        dataMushroom = dataMushroom.replace(\"?\", np.nan)\n",
    "        if featCART:\n",
    "            dataMushroom = dataMushroom[['edible','odor', 'spore-print-color']]\n",
    "        dataFirst, testDataFirst = train_test_split(dataMushroom.dropna(), train_size=0.9, random_state=1)\n",
    "        data, testData = train_test_split(dataFirst, train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        #data = dataMushroom.dropna().sample(n=5, random_state=1).drop(columns=['cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "\n",
    "        trainData = data.drop(columns='edible')\n",
    "        samplePos = (data['edible'] == 'e')*1\n",
    "        samplePosTest = (testData['edible'] == 'e')*1\n",
    "        testData = testData.drop(columns='edible')\n",
    "    elif(datasetname == 'tictactoe'):\n",
    "        dataTicTac = pd.read_csv(\"tic-tac-toe.data\", header=0, names=['top-left-square','top-middle-square','top-right-square','middle-left-square','middle-middle-square','middle-right-square','bottom-left-square','bottom-middle-square','bottom-right-square','Class'])\n",
    "        if featCART:\n",
    "            dataTicTac = dataTicTac[['Class','middle-middle-square','bottom-right-square','top-left-square','middle-right-square','middle-left-square','top-right-square','bottom-left-square','bottom-middle-square']]\n",
    "        dataFirst, testDataFirst = train_test_split(dataTicTac.dropna(), train_size=0.9, random_state=1)\n",
    "        data, testData = train_test_split(dataFirst, train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        samplePos = (data['Class'] == 'positive')*1\n",
    "        trainData = data.drop(columns=['Class'])\n",
    "        samplePosTest = (testData['Class'] == 'positive')*1\n",
    "        testData = testData.drop(columns=['Class'])\n",
    "    elif(datasetname == 'monks'):\n",
    "        dataMonks = pd.read_csv(\"monks-1.test\", header=0, sep=' ', names=['empty','class','a1','a2','a3','a4','a5','a6','Id'])\n",
    "        dataMonks = dataMonks.drop(columns=['empty', 'Id'])\n",
    "        if featCART:\n",
    "            dataMonks = dataMonks[['class','a1', 'a2', 'a4', 'a5']]\n",
    "        for i in dataMonks.columns:\n",
    "            dataMonks[i] = dataMonks[i].apply(str)\n",
    "\n",
    "        dataFirst, testDataFirst = train_test_split(dataMonks.dropna(), train_size = 0.9, random_state=1)\n",
    "\n",
    "        testDataSplit = np.array_split(dataFirst, 5)\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(0, 5):\n",
    "            if i == seed:\n",
    "                testData = testDataSplit[seed]\n",
    "            else:\n",
    "                data = pd.concat([data, testDataSplit[seed]])\n",
    "        \n",
    "        samplePos = (data['class'] == '1')*1\n",
    "        trainData = data.drop(columns=['class'])\n",
    "        samplePosTest = (testData['class'] == '1')*1\n",
    "        testData = testData.drop(columns=['class'])\n",
    "        \n",
    "    elif(datasetname == 'votes'):\n",
    "        dataVotes = pd.read_csv(\"house-votes-84.data\", header=None, names =['Class','handicapped-infants','water-project-cost-sharing','adoption-of-the-budget-resolution','physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports','export-administration-act-south-africa'])\n",
    "        dataVotes = dataVotes.replace(\"?\", np.nan)\n",
    "        if featCART:\n",
    "            dataVotes = dataVotes[['Class','physician-fee-freeze']]\n",
    "        \n",
    "        dataFirst, testDataFirst = train_test_split(dataVotes.dropna(), train_size=0.9, random_state=2)\n",
    "        \n",
    "        testDataSplit = np.array_split(dataFirst, 5)\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(0, 5):\n",
    "            if i == seed:\n",
    "                testData = testDataSplit[seed]\n",
    "            else:\n",
    "                data = pd.concat([data, testDataSplit[seed]])\n",
    "        \n",
    "\n",
    "        samplePos = (data['Class'] == 'democrat')*1\n",
    "        trainData = data.drop(columns='Class')\n",
    "        samplePosTest = (testData['Class'] == 'democrat')*1\n",
    "        testData = testData.drop(columns='Class')\n",
    "    elif(datasetname == 'heart'):\n",
    "        dataHeart1 = pd.read_csv(\"SPECT.test\", header=None)\n",
    "        dataHeart2 = pd.read_csv(\"SPECT.train\", header=None)\n",
    "        frames = [dataHeart1, dataHeart2]\n",
    "        dataHeart = pd.concat(frames)\n",
    "        for i in dataHeart.columns:\n",
    "            dataHeart[i] = dataHeart[i].apply(str)\n",
    "        dataHeart.columns = ['OVERALL_DIAGNOSIS','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22']\n",
    "        if featCART:\n",
    "            dataHeart = dataHeart[['OVERALL_DIAGNOSIS','F13','F11','F16','F10','F22','F20']]\n",
    "        if (sampleAmount > len(dataHeart.dropna())):\n",
    "            sampleAmount = math.floor(len(dataHeart.dropna())*0.9)\n",
    "        dataFirst, testDataFirst = train_test_split(dataHeart.dropna(), train_size=0.9, random_state=1)\n",
    "        \n",
    "        testDataSplit = np.array_split(dataFirst, 5)\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(0, 5):\n",
    "            if i == seed:\n",
    "                testData = testDataSplit[seed]\n",
    "            else:\n",
    "                data = pd.concat([data, testDataSplit[seed]])\n",
    "        \n",
    "        \n",
    "        samplePos = (data['OVERALL_DIAGNOSIS'] == '1')*1\n",
    "        trainData = data.drop(columns='OVERALL_DIAGNOSIS')\n",
    "        samplePosTest = (testData['OVERALL_DIAGNOSIS'] == '1')*1\n",
    "        testData = testData.drop(columns='OVERALL_DIAGNOSIS')\n",
    "    elif(datasetname == 'student'):\n",
    "        studentMat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "        studentMat['nonAlcoholic'] = np.where((studentMat['Dalc'] > 1) & (studentMat['Walc'] > 1), 0, 1)\n",
    "        dataStudent = studentMat.drop(columns=['Walc', 'Dalc'])\n",
    "        if featCART:\n",
    "            dataStudent = dataStudent[['nonAlcoholic','goout','famsize','reason','famsup','studytime','Mjob','activities','sex','famrel','G1']]\n",
    "        if (sampleAmount > len(dataStudent.dropna())):\n",
    "            sampleAmount = math.floor(395*0.9)\n",
    "        dataFirst, testDataFirst = train_test_split(dataStudent.dropna(), train_size=0.9, random_state=1)\n",
    "        \n",
    "        testDataSplit = np.array_split(dataFirst, 5)\n",
    "        data = pd.DataFrame()\n",
    "        for i in range(0, 5):\n",
    "            if i == seed:\n",
    "                testData = testDataSplit[seed]\n",
    "            else:\n",
    "                data = pd.concat([data, testDataSplit[seed]])\n",
    "        \n",
    "        \n",
    "        trainData = data.drop(columns='nonAlcoholic')\n",
    "        samplePos = (data['nonAlcoholic'] == 1)*1    \n",
    "        \n",
    "        samplePosTest = (testData['nonAlcoholic'] == 1)*1\n",
    "        testData = testData.drop(columns='nonAlcoholic')\n",
    "        numericalGroup = [3, 7, 8, 13, 14, 15, 24, 25, 26, 27, 28]\n",
    "    elif(datasetname == 'heloc'):\n",
    "        dataHeloc = pd.read_csv(\"heloc_dataset_v1.csv\", sep=\",\")\n",
    "        if featCART:\n",
    "            dataHeloc = dataHeloc[['RiskPerformance','ExternalRiskEstimate', 'MSinceMostRecentInqexcl7days']]\n",
    "        for i in dataHeloc.columns:\n",
    "            if i != 'RiskPerformance':\n",
    "                dataHeloc[i] = pd.qcut(dataHeloc[i], q=10, duplicates='drop')\n",
    "\n",
    "        data, testData = train_test_split(dataHeloc.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns='RiskPerformance')\n",
    "        samplePos = (data['RiskPerformance'] == 'Good')*1\n",
    "        samplePosTest = (testData['RiskPerformance'] == 'Good')*1\n",
    "        testData = testData.drop(columns='RiskPerformance')\n",
    "        numericalGroup = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "    else:\n",
    "        print('ERROR: dataset name not found')\n",
    "    #process data for tree\n",
    "    if(datasetname == 'heart'):\n",
    "        trainDataDummies = pd.get_dummies(trainData)\n",
    "        testDataDummies = pd.get_dummies(testData)\n",
    "    else:\n",
    "        start = 0\n",
    "        for i in trainData.columns:\n",
    "            if (start == 0):\n",
    "                trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "                trainDataDummies = trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "                start = 1\n",
    "            else:\n",
    "                trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "                trainDataDummies = trainDataDummies.join(trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "        trainDataDummies = trainDataDummies.loc[:, (trainDataDummies != 0).any(axis=0)]\n",
    "\n",
    "        start = 0\n",
    "        for i in testData.columns:\n",
    "            if (start == 0):\n",
    "                testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "                testDataDummies = testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "                start = 1\n",
    "            else:\n",
    "                testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "                testDataDummies = testDataDummies.join(testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "        testDataDummies = testDataDummies.loc[:, (testDataDummies != 0).any(axis=0)]\n",
    "    \n",
    "    groupsN = trainData.shape[1]\n",
    "    G = range(1, groupsN + 1)\n",
    "    groupsOfFeatures = trainData.nunique()\n",
    "    featureToGroup = []\n",
    "    for g in G:\n",
    "        amountOfFeatures = groupsOfFeatures.iloc[g-1]\n",
    "        for f in range(amountOfFeatures):\n",
    "            featureToGroup.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity):\n",
    "    model = Model(\"tree\")\n",
    "    model.parameters.randomseed = 42\n",
    "    \n",
    "    #datashape\n",
    "    N = trainData.shape[0] # amount of samples\n",
    "    I = range(1, N + 1) # all samples\n",
    "    groupsN = trainData.shape[1] # amount of groupes\n",
    "    groupsOfFeatures = trainData.nunique() # amount of features per group\n",
    "    G = range(1, groupsN + 1) #groups\n",
    "    J = range(1, len(trainDataDummies.columns) + 1) #features\n",
    "    Iplus = np.where(samplePos == 1)[0]\n",
    "    Iplus = [x+1 for x in Iplus]\n",
    "    Imin = np.where(samplePos == 0)[0]\n",
    "    Imin = [x+1 for x in Imin]\n",
    "    \n",
    "    \n",
    "    #tree topology\n",
    "    if (typeOfTree == 1):\n",
    "        #simple tree of depth 2\n",
    "        dNodesN = 3\n",
    "        lNodesN = 4\n",
    "        Bplus = [1, 3]\n",
    "        Bmin = [2, 4]\n",
    "        route = np.array([[1, 1, 0], [1, -1, 0], [-1, 0, 1], [-1, 0, -1]])\n",
    "        nonAdjLeaf = [1]\n",
    "        nonAdjLeafSymm = [1]\n",
    "        AdjLeaf = [2, 3]\n",
    "    if(typeOfTree == 2):\n",
    "        #binary tree with depth 2,5\n",
    "        dNodesN = 5\n",
    "        lNodesN = 6\n",
    "        Bplus = [1, 3, 5]\n",
    "        Bmin = [2, 4, 6]\n",
    "        route = np.array([[1, 1, 1, 0, 0], [1, 1, -1, 0, 0], [1, -1, 0, 1, 0], \\\n",
    "                          [1, -1, 0, -1, 0], [-1, 0, 0, 0, 1],  [-1, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2]\n",
    "        nonAdjLeafSymm = [2]\n",
    "        AdjLeaf = [3, 4, 5]\n",
    "    if(typeOfTree == 3):\n",
    "        #binary tree with depth 3\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 0, 0, 0, 0], [1, 1, -1, 0, 0, 0, 0], [1, -1, 0, 1, 0, 0, 0], \\\n",
    "                         [1, -1, 0, -1, 0, 0, 0], [-1, 0, 0, 0, 1, 1, 0], [-1, 0, 0, 0, 1, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, -1, 0, 1], [-1, 0, 0, 0, -1, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 5]\n",
    "        nonAdjLeafSymm = [1, 2, 5]\n",
    "        AdjLeaf = [3, 4, 6, 7]\n",
    "    if(typeOfTree == 4):\n",
    "        #binary tree with depth 3,5\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 1, 0, 0, 0], [1, 1, 1, -1, 0, 0, 0], [1, 1, -1, 0, 1, 0, 0], \\\n",
    "                         [1, 1, -1, 0, -1, 0, 0], [1, -1, 0, 0, 0, 1, 0], [1, -1, 0, 0, 0, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, 0, 0, 1], [-1, 0, 0, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 3]\n",
    "        nonAdjLeafSymm = [3]\n",
    "        AdjLeaf = [4, 5, 6, 7]\n",
    "        \n",
    "    #make nodes\n",
    "    K = range(1, dNodesN + 1) #decision nodes\n",
    "    B = range(1, lNodesN + 1) #leaf nodes\n",
    "\n",
    "    # --- decision variables --- \n",
    "    idv = [(g, k) for g in G for k in K]\n",
    "    if(relax): \n",
    "        v = model.continuous_var_dict(keys=idv, lb=0, ub=1, name=\"V\") #relaxation of variables of paragraph 4.3.4\n",
    "    else:\n",
    "        v = model.binary_var_dict(keys=idv, name=\"V\")\n",
    "    idz = [(j,k) for j in J for k in K]\n",
    "\n",
    "    if(relax):\n",
    "        idzAdjLeaf = [(j,k) for j in J for k in AdjLeaf]\n",
    "        idzNonAdjLeaf = [(j,k) for j in J for k in nonAdjLeaf]\n",
    "        z = model.continuous_var_dict(keys=idzAdjLeaf, lb=0, ub=1, name=\"Z\")\n",
    "        zNonAdjLeaf = model.binary_var_dict(keys=idzNonAdjLeaf, name=\"Z\")\n",
    "        z.update(zNonAdjLeaf)\n",
    "    else:\n",
    "        idz = [(j,k) for j in J for k in K]\n",
    "        z = model.binary_var_dict(keys=idz, name=\"Z\")\n",
    "    idc = [(b,i) for b in B for i in I]\n",
    "    if(relax):\n",
    "        c = model.continuous_var_dict(keys=idc,ub=1, name=\"C\")\n",
    "    else:\n",
    "        c = model.binary_var_dict(keys=idc, name=\"C\")\n",
    "    idL = [(i,k) for i in I for k in K]\n",
    "    L = model.binary_var_dict(keys=idL, name=\"L\")\n",
    "    idR = [(i,k) for i in I for k in K]\n",
    "    R = model.binary_var_dict(keys=idL, name=\"R\")\n",
    "    if(numerical):\n",
    "        idw = [(g,k) for k in K for g in numericalGroup]\n",
    "        w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "    if(combCon):\n",
    "        if(numerical):\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            wcomb = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "            w.update(wcomb)\n",
    "        else:\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "\n",
    "    # --- constraints ---\n",
    "    for k in K:\n",
    "        model.add_constraint(model.sum(v[g, k] for g in G) == 1) #constraint (1)\n",
    "\n",
    "    for k in K:\n",
    "        for j in J:\n",
    "            model.add_constraint(z[j,k] <= v[featureToGroup[j-1], k]) #constraint (2)\n",
    "\n",
    "    for k in K:\n",
    "        for i in I:\n",
    "            model.add_constraint(L[i,k] == sum(z[j,k] for j in J if trainDataDummies.iloc[i-1,j-1] == 1)) #constraint (3)\n",
    "            model.add_constraint(R[i,k] == 1 - L[i,k]) #constraint (4)\n",
    "    \n",
    "    if(strength):\n",
    "        for i in I:\n",
    "            for k in K:\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == 1) <= L[i,k]) #constraint (11)\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == -1) <= R[i,k]) #constraint (12)\n",
    "    else:\n",
    "        for b in B:\n",
    "            for i in I:\n",
    "                for k in K:\n",
    "                    switch = route[b-1, k-1]\n",
    "                    if switch == 1:\n",
    "                        model.add_constraint(c[b,i] <= L[i,k]) #constraint (5)\n",
    "                    elif switch == -1:\n",
    "                        model.add_constraint(c[b,i] <= R[i,k]) #constraint (6)\n",
    "        for i in I:\n",
    "            model.add_constraint(model.sum(c[b,i] for b in B) == 1) #constraint (7)\n",
    "    \n",
    "    if(anchor): \n",
    "        for g in G:\n",
    "            for k in nonAdjLeafSymm: #only for nonleafs with symmatrical subtree\n",
    "                model.add_constraint(z[featureToGroup.index(g) + 1, k] == v[g,k]) #constraint (13)\n",
    "                        \n",
    "    if(ExclSameBranchFollowing):\n",
    "        #for k in K:\n",
    "        test=1\n",
    "            #add constraint (9) and (10)\n",
    "            \n",
    "    if(numerical):\n",
    "        #numerical value constraint 4.4\n",
    "        for k in K:\n",
    "            for g in numericalGroup:\n",
    "                featureList = [i+1 for i, x in enumerate(featureToGroup) if x == g]\n",
    "                if (len(featureList) > 1):\n",
    "                    for j in featureList:\n",
    "                        if(j == featureList[0]):    \n",
    "                            model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                        elif(j == featureList[-1]):\n",
    "                            model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))\n",
    "                        else:\n",
    "                            model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                            model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))                     \n",
    "                \n",
    "    if(combCon):\n",
    "        for k in K:\n",
    "            for g in G:\n",
    "                if((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard)):\n",
    "                    featureList = [i for i, x in enumerate(featureToGroup) if x == g]\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) <= maxCard + (groupsOfFeatures.iloc[g-1] - maxCard)*(1-w[g,k]))\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) >= (groupsOfFeatures.iloc[g-1] - maxCard) - (groupsOfFeatures.iloc[g-1] - maxCard)*w[g,k])\n",
    "        \n",
    "        \n",
    "    \n",
    "    # --- objective ---\n",
    "    model.objectiveTruePos = model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus)\n",
    "    model.objectiveTrueNeg = model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin)\n",
    "    \n",
    "    if(sensOn):\n",
    "        \n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus) >= math.ceil((1-sensitivity)*len(Iplus) ))\n",
    "        \n",
    "        totalObjective = model.objectiveTrueNeg\n",
    "        \n",
    "        sensitivity\n",
    "    elif(specOn):\n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin) >= math.ceil((1-specificity)*len(Imin) ))\n",
    "\n",
    "        totalObjective = model.objectiveTruePos\n",
    "    else:\n",
    "        totalObjective = model.objectiveTruePos + C*model.objectiveTrueNeg \n",
    "    \n",
    "    model.maximize(totalObjective)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeValidation(solution, testDataDummies, trainDataDummies, typeOfTree):\n",
    "    global LikArray\n",
    "    global dfTest\n",
    "    global decNodeFeatureDoubleList\n",
    "    error = False\n",
    "    decNodeFeatureDoubleList = []\n",
    "    decNodeFeatureList = []\n",
    "    \n",
    "    if(typeOfTree == 1):\n",
    "        nodeAmount = 3\n",
    "    elif(typeOfTree == 2):\n",
    "        nodeAmount = 5\n",
    "    elif(typeOfTree == 3):\n",
    "        nodeAmount = 7\n",
    "    elif(typeOfTree == 4):\n",
    "        nodeAmount = 7\n",
    "    for currentNode in range(1, nodeAmount + 1):\n",
    "        for feature in range(1, len(trainDataDummies.columns) + 1):\n",
    "                value = sol.get_value('Z_' + str(feature) + '_' + str(currentNode))\n",
    "                if(value > 0):\n",
    "                    decNodeFeatureList.append(feature)\n",
    "        decNodeFeatureDoubleList.append(decNodeFeatureList)\n",
    "        decNodeFeatureList = []\n",
    "    \n",
    "\n",
    "    dfTest = pd.DataFrame(columns=trainDataDummies.columns)\n",
    "\n",
    "    for col in dfTest.columns:\n",
    "        if col in testDataDummies.columns: # copy columns from testdata to dataframe\n",
    "            dfTest[col] = testDataDummies[col]\n",
    "    dfTest = dfTest.fillna(0) #works\n",
    "    \n",
    "    #first part done\n",
    "    \n",
    "    #now find good route\n",
    "    LikArray = np.zeros((len(dfTest.index), len(decNodeFeatureDoubleList)))\n",
    "    \n",
    "    for i in range(len(dfTest)):\n",
    "        for k in range(len(decNodeFeatureDoubleList)):\n",
    "            #check if Lik equals 1 or 0 \n",
    "                for feature in decNodeFeatureDoubleList[k]:\n",
    "                    if(dfTest.iloc[i,feature-1] == 1):\n",
    "                        LikArray[i,k] = 1\n",
    "                        \n",
    "    totalCorrectClassified = 0\n",
    "    if(typeOfTree == 1):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,3-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "    elif(typeOfTree == 2):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(LikArray[i,3-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                else:\n",
    "                    if(LikArray[i,4-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "            else:\n",
    "                if(LikArray[i,5-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "        \n",
    "        \n",
    "    elif(typeOfTree == 3):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] != 0):\n",
    "                if(LikArray[i,2-1] != 0):\n",
    "                    if(LikArray[i,3-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,4-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,5-1] != 0):\n",
    "                    if(LikArray[i,6-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,7-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "    elif(typeOfTree == 4):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(LikArray[i,3-1] == 1):\n",
    "                        if(LikArray[i,4-1] == 1):\n",
    "                            if(samplePosTest.iloc[i] == 1):\n",
    "                                totalCorrectClassified += 1\n",
    "                        else:\n",
    "                            if(samplePosTest.iloc[i] == 0):\n",
    "                                totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(LikArray[i,5-1] == 1):\n",
    "                            if(samplePosTest.iloc[i] == 1):\n",
    "                                totalCorrectClassified += 1\n",
    "                        else:\n",
    "                            if(samplePosTest.iloc[i] == 0):\n",
    "                                totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,6-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,7-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                    \n",
    "                \n",
    "    else:\n",
    "        print('error treetype not found...')\n",
    "        \n",
    "    return totalCorrectClassified / samplePosTest.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6808f8ce2d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mDataPreperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplesize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatCART\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypeOfTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExclSameBranchFollowing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombCon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxCard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensOn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecOn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_time_limit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a27f3076d650>\u001b[0m in \u001b[0;36mdecisionTree\u001b[1;34m(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJ\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrainDataDummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#constraint (3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#constraint (4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a27f3076d650>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mJ\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrainDataDummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#constraint (3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#constraint (4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2092\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2094\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2095\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m     \u001b[1;31m# raise_missing is included for compat with the parent class signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   2923\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2924\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2925\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2926\u001b[0m             )\n\u001b[0;32m   2927\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1516\u001b[1;33m             \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   3265\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3267\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_ndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmgr_locs\u001b[1;34m(self, new_mgr_locs)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibinternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlockPlacement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solTime = 60*3 #2 minutes\n",
    "C = 1  #weight to objective function\n",
    "ExclSameBranchFollowing = False #constraint (9) and (10)\n",
    "numerical = False\n",
    "combCon = False\n",
    "maxCard = 3\n",
    "sensOn = False\n",
    "specOn = False\n",
    "sensitivity = 0.95\n",
    "specificity = 0.95\n",
    "featCART = True\n",
    "\n",
    "strength = True #constraint (11) and (12)\n",
    "anchor = True #constraint (13)\n",
    "relax = True\n",
    "\n",
    "samplesize = 600\n",
    "datasets = ['adult', 'breast', 'heloc', 'chess', 'mushroom', 'tictactoe' ,'monks', 'votes', 'heart', 'student']\n",
    "datasets = ['monks', 'votes', 'heart', 'student']\n",
    "datasets = ['monks', 'votes', 'heart', 'student']\n",
    "\n",
    "typeOfTrees = [1, 2, 3, 4]\n",
    "\n",
    "runs = 5\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    runRecords = np.zeros((runs, len(typeOfTrees)))\n",
    "    for i in range(0, runs):\n",
    "        for typeOfTree in typeOfTrees:\n",
    "            seed = i\n",
    "\n",
    "            DataPreperation(dataset, samplesize, featCART, seed)\n",
    "\n",
    "            model = decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\n",
    "            model.set_time_limit(solTime)\n",
    "\n",
    "            sol = model.solve()\n",
    "            validation = treeValidation(sol, testDataDummies, trainDataDummies, typeOfTree)\n",
    "            #print(dataset + ' '+ str(seed) + ' '+ str(typeOfTree) + ' '+ str(validation))\n",
    "            runRecords[i, typeOfTree - 1] = validation\n",
    "\n",
    "    avgValidateTree = np.mean(runRecords, axis = 0)\n",
    "    bestTreePerRun = np.argmax(runRecords, axis=1) + 1\n",
    "    bestTree = np.argmax(avgValidateTree) + 1\n",
    "\n",
    "    print(runRecords)\n",
    "    print(avgValidateTree)\n",
    "    print(bestTreePerRun)\n",
    "    print(bestTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n",
      "[[0.79146919 0.7985782  0.77843602 0.80450237]\n",
      " [0.79976303 0.8056872  0.80805687 0.79383886]\n",
      " [0.79976303 0.80331754 0.80924171 0.81398104]\n",
      " [0.79265403 0.77488152 0.79620853 0.75236967]\n",
      " [0.82464455 0.79976303 0.80094787 0.80094787]]\n",
      "[0.80165877 0.7964455  0.7985782  0.79312796]\n",
      "[4 3 4 3 1]\n",
      "1\n",
      "breast\n",
      "[[1.         0.84615385 1.         0.84615385]\n",
      " [0.92307692 0.84615385 0.84615385 0.84615385]\n",
      " [1.         0.92307692 0.84615385 0.92307692]\n",
      " [0.84615385 0.76923077 0.84615385 0.84615385]\n",
      " [1.         0.92307692 0.92307692 0.92307692]]\n",
      "[0.95384615 0.86153846 0.89230769 0.87692308]\n",
      "[1 1 1 1 1]\n",
      "1\n",
      "heloc\n",
      "[[0.70717111 0.70696825 0.70321534 0.70280962]\n",
      " [0.69530378 0.70128816 0.69621665 0.70128816]\n",
      " [0.70351963 0.7044325  0.7044325  0.7044325 ]\n",
      " [0.69226088 0.69297089 0.68445076 0.68445076]\n",
      " [0.70727254 0.68678365 0.69398519 0.68455219]]\n",
      "[0.70110559 0.69848869 0.69646009 0.69550664]\n",
      "[1 2 2 2 1]\n",
      "1\n",
      "chess\n",
      "[[0.8778022  0.94285714 0.94285714 0.94373626]\n",
      " [0.86857143 0.9367033  0.9367033  0.94065934]\n",
      " [0.86901099 0.93802198 0.93802198 0.94197802]\n",
      " [0.87208791 0.9389011  0.9389011  0.94021978]\n",
      " [0.86417582 0.93714286 0.93714286 0.9410989 ]]\n",
      "[0.87032967 0.93872527 0.93872527 0.94153846]\n",
      "[4 4 4 4 4]\n",
      "4\n",
      "mushroom\n",
      "[[0.99418865 0.99418865 0.99418865 0.99418865]\n",
      " [0.99418865 0.99418865 0.99418865 0.99418865]\n",
      " [0.99448666 0.99448666 0.99448666 0.99448666]\n",
      " [0.99403964 0.99403964 0.99403964 0.99403964]\n",
      " [0.99463567 0.99463567 0.99463567 0.99463567]]\n",
      "[0.99430785 0.99430785 0.99430785 0.99430785]\n",
      "[1 1 1 1 1]\n",
      "1\n",
      "tictactoe\n",
      "[[0.69348659 0.72030651 0.74712644 0.70498084]\n",
      " [0.65517241 0.72413793 0.73180077 0.72413793]\n",
      " [0.6743295  0.70498084 0.71264368 0.69348659]\n",
      " [0.69731801 0.72413793 0.7394636  0.73180077]\n",
      " [0.66283525 0.70881226 0.70881226 0.7164751 ]]\n",
      "[0.67662835 0.7164751  0.72796935 0.71417625]\n",
      "[3 3 3 3 4]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "solTime = 60*3 #2 minutes\n",
    "C = 1  #weight to objective function\n",
    "ExclSameBranchFollowing = False #constraint (9) and (10)\n",
    "numerical = False\n",
    "combCon = False\n",
    "maxCard = 3\n",
    "sensOn = False\n",
    "specOn = False\n",
    "sensitivity = 0.95\n",
    "specificity = 0.95\n",
    "featCART = True\n",
    "\n",
    "strength = True #constraint (11) and (12)\n",
    "anchor = True #constraint (13)\n",
    "relax = True\n",
    "\n",
    "samplesize = 600\n",
    "datasets = ['adult', 'breast', 'heloc', 'chess', 'mushroom', 'tictactoe']\n",
    "\n",
    "typeOfTrees = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "runs = 5\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    runRecords = np.zeros((runs, len(typeOfTrees)))\n",
    "    for i in range(0, runs):\n",
    "        for typeOfTree in typeOfTrees:\n",
    "            seed = i\n",
    "\n",
    "            DataPreperation(dataset, samplesize, featCART, seed)\n",
    "\n",
    "            model = decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\n",
    "            model.set_time_limit(solTime)\n",
    "\n",
    "            sol = model.solve()\n",
    "            validation = treeValidation(sol, testDataDummies, trainDataDummies, typeOfTree)\n",
    "            #print(dataset + ' '+ str(seed) + ' '+ str(typeOfTree) + ' '+ str(validation))\n",
    "            runRecords[i, typeOfTree - 1] = validation\n",
    "\n",
    "    avgValidateTree = np.mean(runRecords, axis = 0)\n",
    "    bestTreePerRun = np.argmax(runRecords, axis=1) + 1\n",
    "    bestTree = np.argmax(avgValidateTree) + 1\n",
    "\n",
    "    print(runRecords)\n",
    "    print(avgValidateTree)\n",
    "    print(bestTreePerRun)\n",
    "    print(bestTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
