{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import docplex\n",
    "from docplex.mp.model import Model\n",
    "from docplex.mp.progress import *\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreperation(datasetname,sampleAmount, featCART, seed, featChi, treeType):\n",
    "    global numericalGroup\n",
    "    numericalGroup = []\n",
    "    global data\n",
    "    global trainData\n",
    "    global samplePos\n",
    "    global trainDataDummies\n",
    "    global groupsOfFeatures\n",
    "    global featureToGroup\n",
    "    global testData\n",
    "    global testDataDummies\n",
    "    global samplePosTest\n",
    "    \n",
    "    if(treeType == 1):\n",
    "        decNodeAmount = 3\n",
    "    elif(treeType == 2):\n",
    "        decNodeAmount = 5\n",
    "    elif(treeType == 3):\n",
    "        decNodeAmount = 7\n",
    "    elif(treeType == 4):\n",
    "        decNodeAmount = 7\n",
    "    else: \n",
    "        print('ERROR: treetype not found!' )\n",
    "    # Read in dataset\n",
    "    if(datasetname == 'chess'):\n",
    "        dataChess = pd.read_csv(\"kr-vs-kp.data\", header=0, names=['bkblk','bknwy','bkon8','bkona','bkspr','bkxbq','bkxcr','bkxwp','blxwp','bxqsq','cntxt','dsopp','dwipd','hdchk','katri','mulch','qxmsq','r2ar8','reskd','reskr','rimmx','rkxwp','rxmsq','simpl','skach','skewr','skrxp','spcop','stlmt','thrsk','wkcti','wkna8','wknck','wkovl','wkpos','wtoeg','white_win'])\n",
    "        if featCART:\n",
    "            dataChess = dataChess[['white_win','rimmx','wknck','bxqsq','wkna8', 'wkpos','bkxbq','katri', 'bkblk']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['white_win','rimmx', 'bxqsq', 'wknck', 'bkxwp', 'katri', 'wkna8', 'r2ar8']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataChess = dataChess[selectedGroups]\n",
    "        data, testData = train_test_split(dataChess.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns=['white_win'])\n",
    "        samplePos = (data['white_win'] == 'won')*1\n",
    "        samplePosTest = (testData['white_win'] == 'won')*1\n",
    "        testData = testData.drop(columns='white_win')\n",
    "    elif(datasetname == 'adult'):\n",
    "        dataAdult = pd.read_csv(\"a1a.txt\", delim_whitespace=True, header=None, names = ['salary50k','age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country']) \n",
    "        if featCART:\n",
    "            dataAdult = dataAdult[['salary50k','relationship', 'occupation', 'education', 'capital-gain','workclass']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['salary50k', 'relationship', 'marital-status', 'education', 'education-num', 'occupation', 'age', 'capital-gain']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataAdult = dataAdult[selectedGroups]    \n",
    "        data, testData = train_test_split(dataAdult.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns='salary50k')\n",
    "        samplePos = (data['salary50k'] == 1)*1\n",
    "        \n",
    "        samplePosTest = (testData['salary50k'] == 1)*1\n",
    "        testData = testData.drop(columns='salary50k')\n",
    "        \n",
    "        numericalGroup = [1, 3, 5, 11, 12, 13]\n",
    "    elif(datasetname == 'breast'):\n",
    "        dataBreast = pd.read_csv(\"breast.txt\", delim_whitespace=True, header=0, names=['Class','Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses'])\n",
    "        dataBreast = dataBreast.drop(columns='Sample code number') #drop id-numbers of observations\n",
    "        if featCART:\n",
    "            dataBreast = dataBreast[['Class','Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Bare Nuclei']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['Class', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Bare Nuclei', 'Bland Chromatin', 'Single Epithelial Cell Size', 'Normal Nucleoli', 'Marginal Adhesion']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataBreast = dataBreast[selectedGroups] \n",
    "        data, testData = train_test_split(dataBreast.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        #for i in trainData.columns: #take away the rownumber: of all variables.\n",
    "        #        trainData[i] = trainData[i].str[trainData.iloc[0][i].index(':')+1:]\n",
    "        samplePos = (data['Class'] == 2)*1\n",
    "        trainData = data.drop(columns='Class')\n",
    "        \n",
    "        samplePosTest = (testData['Class'] == 2)*1\n",
    "        testData = testData.drop(columns='Class')\n",
    "        \n",
    "        numericalGroup = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    elif(datasetname == 'mushroom'):\n",
    "        dataMushroom = pd.read_csv(\"agaricus-lepiota.data\", header=0, names=['edible','cap-shape','cap-surface','cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "        dataMushroom = dataMushroom.replace(\"?\", np.nan)\n",
    "        if featCART:\n",
    "            dataMushroom = dataMushroom[['edible','odor', 'spore-print-color']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['edible', 'odor', 'spore-print-color', 'gill-color', 'ring-type', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'gill-size']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataMushroom = dataMushroom[selectedGroups] \n",
    "            \n",
    "        data, testData = train_test_split(dataMushroom.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        #data = dataMushroom.dropna().sample(n=5, random_state=1).drop(columns=['cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat'])\n",
    "\n",
    "        trainData = data.drop(columns='edible')\n",
    "        samplePos = (data['edible'] == 'e')*1\n",
    "        samplePosTest = (testData['edible'] == 'e')*1\n",
    "        testData = testData.drop(columns='edible')\n",
    "    elif(datasetname == 'tictactoe'):\n",
    "        dataTicTac = pd.read_csv(\"tic-tac-toe.data\", header=0, names=['top-left-square','top-middle-square','top-right-square','middle-left-square','middle-middle-square','middle-right-square','bottom-left-square','bottom-middle-square','bottom-right-square','Class'])\n",
    "        if featCART:\n",
    "            dataTicTac = dataTicTac[['Class','middle-middle-square','bottom-right-square','top-left-square','middle-right-square','middle-left-square','top-right-square','bottom-left-square','bottom-middle-square']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['Class', 'middle-middle-square', 'bottom-right-square', 'bottom-left-square', 'top-right-square', 'top-left-square', 'bottom-middle-square', 'middle-right-square']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataTicTac = dataTicTac[selectedGroups]\n",
    "        data, testData = train_test_split(dataTicTac.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        samplePos = (data['Class'] == 'positive')*1\n",
    "        trainData = data.drop(columns=['Class'])\n",
    "        samplePosTest = (testData['Class'] == 'positive')*1\n",
    "        testData = testData.drop(columns=['Class'])\n",
    "    elif(datasetname == 'monks'):\n",
    "        dataMonks = pd.read_csv(\"monks-1.test\", header=0, sep=' ', names=['empty','class','a1','a2','a3','a4','a5','a6','Id'])\n",
    "        dataMonks = dataMonks.drop(columns=['empty', 'Id'])\n",
    "        if featCART:\n",
    "            dataMonks = dataMonks[['class','a1', 'a2', 'a4', 'a5']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['class', 'a5', 'a6','a4', 'a3', 'a2', 'a1']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataMonks = dataMonks[selectedGroups]\n",
    "        for i in dataMonks.columns:\n",
    "            dataMonks[i] = dataMonks[i].apply(str)\n",
    "        if(sampleAmount > len(dataMonks.dropna())):\n",
    "            sampleAmount = math.floor(len(dataMonks)*0.9)\n",
    "        data, testData = train_test_split(dataMonks.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "\n",
    "        samplePos = (data['class'] == '1')*1\n",
    "        trainData = data.drop(columns=['class'])\n",
    "        samplePosTest = (testData['class'] == '1')*1\n",
    "        testData = testData.drop(columns=['class'])\n",
    "    elif(datasetname == 'votes'):\n",
    "        dataVotes = pd.read_csv(\"house-votes-84.data\", header=None, names =['Class','handicapped-infants','water-project-cost-sharing','adoption-of-the-budget-resolution','physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports','export-administration-act-south-africa'])\n",
    "        dataVotes = dataVotes.replace(\"?\", np.nan)\n",
    "        if featCART:\n",
    "            dataVotes = dataVotes[['Class','physician-fee-freeze']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['Class', 'physician-fee-freeze', 'adoption-of-the-budget-resolution','el-salvador-aid', 'education-spending', 'aid-to-nicaraguan-contras', 'mx-missile', 'crime']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataVotes = dataVotes[selectedGroups]\n",
    "        if(sampleAmount > len(dataVotes.dropna())):\n",
    "            sampleAmount = math.floor(len(dataVotes.dropna())*0.9)\n",
    "        data, testData = train_test_split(dataVotes.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "\n",
    "        samplePos = (data['Class'] == 'democrat')*1\n",
    "        trainData = data.drop(columns='Class')\n",
    "        samplePosTest = (testData['Class'] == 'democrat')*1\n",
    "        testData = testData.drop(columns='Class')\n",
    "    elif(datasetname == 'heart'):\n",
    "        dataHeart1 = pd.read_csv(\"SPECT.test\", header=None)\n",
    "        dataHeart2 = pd.read_csv(\"SPECT.train\", header=None)\n",
    "        frames = [dataHeart1, dataHeart2]\n",
    "        dataHeart = pd.concat(frames)\n",
    "        for i in dataHeart.columns:\n",
    "            dataHeart[i] = dataHeart[i].apply(str)\n",
    "        dataHeart.columns = ['OVERALL_DIAGNOSIS','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12','F13','F14','F15','F16','F17','F18','F19','F20','F21','F22']\n",
    "        if featCART:\n",
    "            dataHeart = dataHeart[['OVERALL_DIAGNOSIS','F13','F11','F16','F10','F22','F20']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['OVERALL_DIAGNOSIS', 'F13', 'F8','F21', 'F22', 'F16', 'F20', 'F3']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataHeart = dataHeart[selectedGroups]\n",
    "        if (sampleAmount > len(dataHeart.dropna())):\n",
    "            sampleAmount = math.floor(len(dataHeart.dropna())*0.9)\n",
    "        data, testData = train_test_split(dataHeart.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        samplePos = (data['OVERALL_DIAGNOSIS'] == '1')*1\n",
    "        trainData = data.drop(columns='OVERALL_DIAGNOSIS')\n",
    "        samplePosTest = (testData['OVERALL_DIAGNOSIS'] == '1')*1\n",
    "        testData = testData.drop(columns='OVERALL_DIAGNOSIS')\n",
    "    elif(datasetname == 'student'):\n",
    "        studentMat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "        studentMat['nonAlcoholic'] = np.where((studentMat['Dalc'] > 1) & (studentMat['Walc'] > 1), 0, 1)\n",
    "        dataStudent = studentMat.drop(columns=['Walc', 'Dalc'])\n",
    "        if featCART:\n",
    "            dataStudent = dataStudent[['nonAlcoholic','goout','famsize','reason','famsup','studytime','famsize','Mjob','activities','sex','famrel','G1']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['nonAlcoholic', 'absences', 'goout','G3', 'G1', 'sex', 'G2', 'failures']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataStudent = dataStudent[selectedGroups]\n",
    "        if (sampleAmount > len(dataStudent.dropna())):\n",
    "            sampleAmount = math.floor(395*0.9)\n",
    "        data, testData = train_test_split(dataStudent.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        \n",
    "        trainData = data.drop(columns='nonAlcoholic')\n",
    "        samplePos = (data['nonAlcoholic'] == 1)*1    \n",
    "        \n",
    "        samplePosTest = (testData['nonAlcoholic'] == 1)*1\n",
    "        testData = testData.drop(columns='nonAlcoholic')\n",
    "        numericalGroup = [3, 7, 8, 13, 14, 15, 24, 25, 26, 27, 28]\n",
    "    elif(datasetname == 'heloc'):\n",
    "        dataHeloc = pd.read_csv(\"heloc_dataset_v1.csv\", sep=\",\")\n",
    "        if featCART:\n",
    "            dataHeloc = dataHeloc[['RiskPerformance','ExternalRiskEstimate', 'MSinceMostRecentInqexcl7days']]\n",
    "        elif featChi:\n",
    "            bestGroups = ['RiskPerformance', 'ExternalRiskEstimate', 'NetFractionRevolvingBurden','NumBank2NatlTradesWHighUtilization', 'PercentTradesNeverDelq', 'MaxDelq2PublicRecLast12M', 'MSinceMostRecentDelq', 'PercentTradesWBalance']\n",
    "            selectedGroups = bestGroups[:decNodeAmount+1]\n",
    "            dataHeloc = dataHeloc[selectedGroups]\n",
    "        for i in dataHeloc.columns:\n",
    "            if i != 'RiskPerformance':\n",
    "                dataHeloc[i] = pd.qcut(dataHeloc[i], q=10, duplicates='drop')\n",
    "\n",
    "        data, testData = train_test_split(dataHeloc.dropna(), train_size=sampleAmount, random_state=seed)\n",
    "        trainData = data.drop(columns='RiskPerformance')\n",
    "        samplePos = (data['RiskPerformance'] == 'Good')*1\n",
    "        samplePosTest = (testData['RiskPerformance'] == 'Good')*1\n",
    "        testData = testData.drop(columns='RiskPerformance')\n",
    "        numericalGroup = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "    else:\n",
    "        print('ERROR: dataset name not found')\n",
    "    #process data for tree\n",
    "    if(datasetname == 'heart'):\n",
    "        trainDataDummies = pd.get_dummies(trainData)\n",
    "        testDataDummies = pd.get_dummies(testData)\n",
    "    else:\n",
    "        start = 0\n",
    "        for i in trainData.columns:\n",
    "            if (start == 0):\n",
    "                trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "                trainDataDummies = trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "                start = 1\n",
    "            else:\n",
    "                trainDataDummiesTemp = pd.get_dummies(trainData[i], prefix=i)\n",
    "                trainDataDummies = trainDataDummies.join(trainDataDummiesTemp[sorted(trainDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "        trainDataDummies = trainDataDummies.loc[:, (trainDataDummies != 0).any(axis=0)]\n",
    "\n",
    "        start = 0\n",
    "        for i in testData.columns:\n",
    "            if (start == 0):\n",
    "                testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "                testDataDummies = testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)]\n",
    "                start = 1\n",
    "            else:\n",
    "                testDataDummiesTemp = pd.get_dummies(testData[i], prefix=i)\n",
    "                testDataDummies = testDataDummies.join(testDataDummiesTemp[sorted(testDataDummiesTemp.columns.tolist(), key=str.lower)])\n",
    "        testDataDummies = testDataDummies.loc[:, (testDataDummies != 0).any(axis=0)]\n",
    "    \n",
    "    groupsN = trainData.shape[1]\n",
    "    G = range(1, groupsN + 1)\n",
    "    groupsOfFeatures = trainData.nunique()\n",
    "    featureToGroup = []\n",
    "    for g in G:\n",
    "        amountOfFeatures = groupsOfFeatures.iloc[g-1]\n",
    "        for f in range(amountOfFeatures):\n",
    "            featureToGroup.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity):\n",
    "    model = Model(\"tree\")\n",
    "    model.parameters.randomseed = 42\n",
    "    \n",
    "    #datashape\n",
    "    N = trainData.shape[0] # amount of samples\n",
    "    I = range(1, N + 1) # all samples\n",
    "    groupsN = trainData.shape[1] # amount of groupes\n",
    "    groupsOfFeatures = trainData.nunique() # amount of features per group\n",
    "    G = range(1, groupsN + 1) #groups\n",
    "    J = range(1, len(trainDataDummies.columns) + 1) #features\n",
    "    Iplus = np.where(samplePos == 1)[0]\n",
    "    Iplus = [x+1 for x in Iplus]\n",
    "    Imin = np.where(samplePos == 0)[0]\n",
    "    Imin = [x+1 for x in Imin]\n",
    "    \n",
    "    \n",
    "    #tree topology\n",
    "    if (typeOfTree == 1):\n",
    "        #simple tree of depth 2\n",
    "        dNodesN = 3\n",
    "        lNodesN = 4\n",
    "        Bplus = [1, 3]\n",
    "        Bmin = [2, 4]\n",
    "        route = np.array([[1, 1, 0], [1, -1, 0], [-1, 0, 1], [-1, 0, -1]])\n",
    "        nonAdjLeaf = [1]\n",
    "        nonAdjLeafSymm = [1]\n",
    "        AdjLeaf = [2, 3]\n",
    "    if(typeOfTree == 2):\n",
    "        #binary tree with depth 2,5\n",
    "        dNodesN = 5\n",
    "        lNodesN = 6\n",
    "        Bplus = [1, 3, 5]\n",
    "        Bmin = [2, 4, 6]\n",
    "        route = np.array([[1, 1, 1, 0, 0], [1, 1, -1, 0, 0], [1, -1, 0, 1, 0], \\\n",
    "                          [1, -1, 0, -1, 0], [-1, 0, 0, 0, 1],  [-1, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2]\n",
    "        nonAdjLeafSymm = [2]\n",
    "        AdjLeaf = [3, 4, 5]\n",
    "    if(typeOfTree == 3):\n",
    "        #binary tree with depth 3\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 0, 0, 0, 0], [1, 1, -1, 0, 0, 0, 0], [1, -1, 0, 1, 0, 0, 0], \\\n",
    "                         [1, -1, 0, -1, 0, 0, 0], [-1, 0, 0, 0, 1, 1, 0], [-1, 0, 0, 0, 1, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, -1, 0, 1], [-1, 0, 0, 0, -1, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 5]\n",
    "        nonAdjLeafSymm = [1, 2, 5]\n",
    "        AdjLeaf = [3, 4, 6, 7]\n",
    "    if(typeOfTree == 4):\n",
    "        #binary tree with depth 3,5\n",
    "        dNodesN = 7\n",
    "        lNodesN = 8\n",
    "        Bplus = [1, 3, 5, 7]\n",
    "        Bmin = [2, 4, 6, 8]\n",
    "        route = np.array([[1, 1, 1, 1, 0, 0, 0], [1, 1, 1, -1, 0, 0, 0], [1, 1, -1, 0, 1, 0, 0], \\\n",
    "                         [1, 1, -1, 0, -1, 0, 0], [1, -1, 0, 0, 0, 1, 0], [1, -1, 0, 0, 0, -1, 0], \\\n",
    "                         [-1, 0, 0, 0, 0, 0, 1], [-1, 0, 0, 0, 0, 0, -1]])\n",
    "        nonAdjLeaf = [1, 2, 3]\n",
    "        nonAdjLeafSymm = [3]\n",
    "        AdjLeaf = [4, 5, 6, 7]\n",
    "        \n",
    "    #make nodes\n",
    "    K = range(1, dNodesN + 1) #decision nodes\n",
    "    B = range(1, lNodesN + 1) #leaf nodes\n",
    "\n",
    "    # --- decision variables --- \n",
    "    idv = [(g, k) for g in G for k in K]\n",
    "    if(relax): \n",
    "        v = model.continuous_var_dict(keys=idv, lb=0, ub=1, name=\"V\") #relaxation of variables of paragraph 4.3.4\n",
    "    else:\n",
    "        v = model.binary_var_dict(keys=idv, name=\"V\")\n",
    "    idz = [(j,k) for j in J for k in K]\n",
    "\n",
    "    if(relax):\n",
    "        idzAdjLeaf = [(j,k) for j in J for k in AdjLeaf]\n",
    "        idzNonAdjLeaf = [(j,k) for j in J for k in nonAdjLeaf]\n",
    "        z = model.continuous_var_dict(keys=idzAdjLeaf, lb=0, ub=1, name=\"Z\")\n",
    "        zNonAdjLeaf = model.binary_var_dict(keys=idzNonAdjLeaf, name=\"Z\")\n",
    "        z.update(zNonAdjLeaf)\n",
    "    else:\n",
    "        idz = [(j,k) for j in J for k in K]\n",
    "        z = model.binary_var_dict(keys=idz, name=\"Z\")\n",
    "    idc = [(b,i) for b in B for i in I]\n",
    "    if(relax):\n",
    "        c = model.continuous_var_dict(keys=idc,ub=1, name=\"C\")\n",
    "    else:\n",
    "        c = model.binary_var_dict(keys=idc, name=\"C\")\n",
    "    idL = [(i,k) for i in I for k in K]\n",
    "    L = model.binary_var_dict(keys=idL, name=\"L\")\n",
    "    idR = [(i,k) for i in I for k in K]\n",
    "    R = model.binary_var_dict(keys=idL, name=\"R\")\n",
    "    if(numerical):\n",
    "        idw = [(g,k) for k in K for g in numericalGroup]\n",
    "        w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "    if(combCon):\n",
    "        if(numerical):\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            wcomb = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "            w.update(wcomb)\n",
    "        else:\n",
    "            idw = [(g,k) for k in K for g in G if ((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard))]\n",
    "            w = model.binary_var_dict(keys=idw, name=\"W\")\n",
    "\n",
    "    # --- constraints ---\n",
    "    for k in K:\n",
    "        model.add_constraint(model.sum(v[g, k] for g in G) == 1) #constraint (1)\n",
    "\n",
    "    for k in K:\n",
    "        for j in J:\n",
    "            model.add_constraint(z[j,k] <= v[featureToGroup[j-1], k]) #constraint (2)\n",
    "\n",
    "    for k in K:\n",
    "        for i in I:\n",
    "            model.add_constraint(L[i,k] == sum(z[j,k] for j in J if trainDataDummies.iloc[i-1,j-1] == 1)) #constraint (3)\n",
    "            model.add_constraint(R[i,k] == 1 - L[i,k]) #constraint (4)\n",
    "    \n",
    "    if(strength):\n",
    "        for i in I:\n",
    "            for k in K:\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == 1) <= L[i,k]) #constraint (11)\n",
    "                model.add_constraint(sum(c[b,i] for b in B if route[b-1, k-1] == -1) <= R[i,k]) #constraint (12)\n",
    "    else:\n",
    "        for b in B:\n",
    "            for i in I:\n",
    "                for k in K:\n",
    "                    switch = route[b-1, k-1]\n",
    "                    if switch == 1:\n",
    "                        model.add_constraint(c[b,i] <= L[i,k]) #constraint (5)\n",
    "                    elif switch == -1:\n",
    "                        model.add_constraint(c[b,i] <= R[i,k]) #constraint (6)\n",
    "        for i in I:\n",
    "            model.add_constraint(model.sum(c[b,i] for b in B) == 1) #constraint (7)\n",
    "    \n",
    "    if(anchor): \n",
    "        for g in G:\n",
    "            for k in nonAdjLeafSymm: #only for nonleafs with symmatrical subtree\n",
    "                model.add_constraint(z[featureToGroup.index(g) + 1, k] == v[g,k]) #constraint (13)\n",
    "                        \n",
    "    if(ExclSameBranchFollowing):\n",
    "        #for k in K:\n",
    "        test=1\n",
    "            #add constraint (9) and (10)\n",
    "            \n",
    "    if(numerical):\n",
    "        #numerical value constraint 4.4\n",
    "        for k in K:\n",
    "            for g in numericalGroup:\n",
    "                featureList = [i+1 for i, x in enumerate(featureToGroup) if x == g]\n",
    "                if (len(featureList) > 1):\n",
    "                    for j in featureList:\n",
    "                        if(j == featureList[0]):    \n",
    "                            model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                        elif(j == featureList[-1]):\n",
    "                            model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))\n",
    "                        else:\n",
    "                            model.add_constraint(z[j,k] >= z[j+1,k] - w[g,k])\n",
    "                            model.add_constraint(z[j,k] >= z[j-1,k] - (1 - w[g,k]))                     \n",
    "                \n",
    "    if(combCon):\n",
    "        for k in K:\n",
    "            for g in G:\n",
    "                if((g not in numericalGroup) and (groupsOfFeatures.iloc[g-1] > maxCard)):\n",
    "                    featureList = [i for i, x in enumerate(featureToGroup) if x == g]\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) <= maxCard + (groupsOfFeatures.iloc[g-1] - maxCard)*(1-w[g,k]))\n",
    "                    model.add_constraint(model.sum(z[j+1,k] for j in featureList) >= (groupsOfFeatures.iloc[g-1] - maxCard) - (groupsOfFeatures.iloc[g-1] - maxCard)*w[g,k])\n",
    "        \n",
    "        \n",
    "    \n",
    "    # --- objective ---\n",
    "    model.objectiveTruePos = model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus)\n",
    "    model.objectiveTrueNeg = model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin)\n",
    "    \n",
    "    if(sensOn):\n",
    "        \n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bplus) for i in Iplus) >= math.ceil((1-sensitivity)*len(Iplus) ))\n",
    "        \n",
    "        totalObjective = model.objectiveTrueNeg\n",
    "        \n",
    "        sensitivity\n",
    "    elif(specOn):\n",
    "        model.add_constraint(model.sum(model.sum(c[b,i] for b in Bmin) for i in Imin) >= math.ceil((1-specificity)*len(Imin) ))\n",
    "\n",
    "        totalObjective = model.objectiveTruePos\n",
    "    else:\n",
    "        totalObjective = model.objectiveTruePos + C*model.objectiveTrueNeg \n",
    "    \n",
    "    model.maximize(totalObjective)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeValidation(solution, testDataDummies, trainDataDummies, typeOfTree):\n",
    "    global LikArray\n",
    "    global dfTest\n",
    "    global decNodeFeatureDoubleList\n",
    "    error = False\n",
    "    decNodeFeatureDoubleList = []\n",
    "    decNodeFeatureList = []\n",
    "    \n",
    "    if(typeOfTree == 1):\n",
    "        nodeAmount = 3\n",
    "    elif(typeOfTree == 2):\n",
    "        nodeAmount = 5\n",
    "    elif(typeOfTree == 3):\n",
    "        nodeAmount = 7\n",
    "    elif(typeOfTree == 4):\n",
    "        nodeAmount = 7\n",
    "    for currentNode in range(1, nodeAmount + 1):\n",
    "        for feature in range(1, len(trainDataDummies.columns) + 1):\n",
    "                value = sol.get_value('Z_' + str(feature) + '_' + str(currentNode))\n",
    "                if(value > 0):\n",
    "                    decNodeFeatureList.append(feature)\n",
    "        decNodeFeatureDoubleList.append(decNodeFeatureList)\n",
    "        decNodeFeatureList = []\n",
    "    \n",
    "\n",
    "    dfTest = pd.DataFrame(columns=trainDataDummies.columns)\n",
    "\n",
    "    for col in dfTest.columns:\n",
    "        if col in testDataDummies.columns: # copy columns from testdata to dataframe\n",
    "            dfTest[col] = testDataDummies[col]\n",
    "    dfTest = dfTest.fillna(0) #works\n",
    "    \n",
    "    #first part done\n",
    "    \n",
    "    #now find good route\n",
    "    LikArray = np.zeros((len(dfTest.index), len(decNodeFeatureDoubleList)))\n",
    "    \n",
    "    for i in range(len(dfTest)):\n",
    "        for k in range(len(decNodeFeatureDoubleList)):\n",
    "            #check if Lik equals 1 or 0 \n",
    "                for feature in decNodeFeatureDoubleList[k]:\n",
    "                    if(dfTest.iloc[i,feature-1] == 1):\n",
    "                        LikArray[i,k] = 1\n",
    "                        \n",
    "    totalCorrectClassified = 0\n",
    "    if(typeOfTree == 1):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,3-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "    elif(typeOfTree == 2):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(LikArray[i,3-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                else:\n",
    "                    if(LikArray[i,4-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                            \n",
    "            else:\n",
    "                if(LikArray[i,5-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                        \n",
    "        \n",
    "        \n",
    "    elif(typeOfTree == 3):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] != 0):\n",
    "                if(LikArray[i,2-1] != 0):\n",
    "                    if(LikArray[i,3-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,4-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,5-1] != 0):\n",
    "                    if(LikArray[i,6-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,7-1] != 0):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "    elif(typeOfTree == 4):\n",
    "        for i in range(len(dfTest)):\n",
    "            if(LikArray[i,1-1] == 1):\n",
    "                if(LikArray[i,2-1] == 1):\n",
    "                    if(LikArray[i,3-1] == 1):\n",
    "                        if(LikArray[i,4-1] == 1):\n",
    "                            if(samplePosTest.iloc[i] == 1):\n",
    "                                totalCorrectClassified += 1\n",
    "                        else:\n",
    "                            if(samplePosTest.iloc[i] == 0):\n",
    "                                totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(LikArray[i,5-1] == 1):\n",
    "                            if(samplePosTest.iloc[i] == 1):\n",
    "                                totalCorrectClassified += 1\n",
    "                        else:\n",
    "                            if(samplePosTest.iloc[i] == 0):\n",
    "                                totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(LikArray[i,6-1] == 1):\n",
    "                        if(samplePosTest.iloc[i] == 1):\n",
    "                            totalCorrectClassified += 1\n",
    "                    else:\n",
    "                        if(samplePosTest.iloc[i] == 0):\n",
    "                            totalCorrectClassified += 1\n",
    "            else:\n",
    "                if(LikArray[i,7-1] == 1):\n",
    "                    if(samplePosTest.iloc[i] == 1):\n",
    "                        totalCorrectClassified += 1\n",
    "                else:\n",
    "                    if(samplePosTest.iloc[i] == 0):\n",
    "                        totalCorrectClassified += 1\n",
    "                    \n",
    "                \n",
    "    else:\n",
    "        print('error treetype not found...')\n",
    "        \n",
    "    return totalCorrectClassified / samplePosTest.size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heloc 0.9 1 results: 70.40263465420163 (69.12045889101339)/147.40700000000652\n"
     ]
    }
   ],
   "source": [
    "solTime = 60*10 #2 minutes\n",
    "\n",
    "C = 1  #weight to objective function\n",
    "ExclSameBranchFollowing = False #constraint (9) and (10)\n",
    "numerical = False\n",
    "combCon = False\n",
    "maxCard = 3\n",
    "sensOn = False\n",
    "specOn = False\n",
    "sensitivity = 0.95\n",
    "specificity = 0.95\n",
    "featCART = False\n",
    "featChi = True\n",
    "\n",
    "strength = True #constraint (11) and (12)\n",
    "anchor = True #constraint (13)\n",
    "relax = True\n",
    "\n",
    "samplesize = 0.9\n",
    "dataset = 'heloc'\n",
    "\n",
    "typeOfTree = 1\n",
    "\n",
    "seed = 1\n",
    "\n",
    "\n",
    "\n",
    "DataPreperation(dataset,samplesize, featCART, seed, featChi, typeOfTree)\n",
    "\n",
    "model = decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\n",
    "model.set_time_limit(solTime)\n",
    "\n",
    "sol = model.solve()\n",
    "\n",
    "objValue = sol.get_objective_value()\n",
    "\n",
    "validation = treeValidation(sol, testDataDummies, trainDataDummies, typeOfTree)\n",
    "\n",
    "print(dataset +' ' + str(samplesize) +' '+ str(typeOfTree) +' results: '+ str(objValue / len(samplePos) * 100) + ' (' + str(validation*100) + ')' + '/' + str(model.solve_details.time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heloc 0.9 1 results: 71.33751195155635 (70.26768642447419)/103.01600000000326\n"
     ]
    }
   ],
   "source": [
    "solTime = 60*10 #2 minutes\n",
    "\n",
    "C = 1  #weight to objective function\n",
    "ExclSameBranchFollowing = False #constraint (9) and (10)\n",
    "numerical = False\n",
    "combCon = False\n",
    "maxCard = 3\n",
    "sensOn = False\n",
    "specOn = False\n",
    "sensitivity = 0.95\n",
    "specificity = 0.95\n",
    "featCART = True\n",
    "featChi = False\n",
    "\n",
    "strength = True #constraint (11) and (12)\n",
    "anchor = True #constraint (13)\n",
    "relax = True\n",
    "\n",
    "samplesize = 0.9\n",
    "dataset = 'heloc'\n",
    "\n",
    "typeOfTree = 1\n",
    "\n",
    "seed = 1\n",
    "\n",
    "\n",
    "\n",
    "DataPreperation(dataset,samplesize, featCART, seed, featChi, typeOfTree)\n",
    "\n",
    "model = decisionTree(typeOfTree, C, ExclSameBranchFollowing, strength, anchor, relax, numerical, combCon, maxCard, sensOn, specOn, sensitivity, specificity)\n",
    "model.set_time_limit(solTime)\n",
    "\n",
    "sol = model.solve()\n",
    "\n",
    "objValue = sol.get_objective_value()\n",
    "\n",
    "validation = treeValidation(sol, testDataDummies, trainDataDummies, typeOfTree)\n",
    "\n",
    "print(dataset +' ' + str(samplesize) +' '+ str(typeOfTree) +' results: '+ str(objValue / len(samplePos) * 100) + ' (' + str(validation*100) + ')' + '/' + str(model.solve_details.time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4648</td>\n",
       "      <td>(65.0, 68.0]</td>\n",
       "      <td>(-9.001, 0.0]</td>\n",
       "      <td>(-9.001, -8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3501</td>\n",
       "      <td>(74.0, 78.0]</td>\n",
       "      <td>(0.0, 3.0]</td>\n",
       "      <td>(-8.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7616</td>\n",
       "      <td>(61.0, 65.0]</td>\n",
       "      <td>(47.0, 60.0]</td>\n",
       "      <td>(1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8056</td>\n",
       "      <td>(65.0, 68.0]</td>\n",
       "      <td>(3.0, 8.0]</td>\n",
       "      <td>(-8.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5783</td>\n",
       "      <td>(56.0, 61.0]</td>\n",
       "      <td>(36.0, 47.0]</td>\n",
       "      <td>(-8.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2052</td>\n",
       "      <td>(56.0, 61.0]</td>\n",
       "      <td>(-9.001, 0.0]</td>\n",
       "      <td>(-9.001, -8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2813</td>\n",
       "      <td>(81.0, 86.0]</td>\n",
       "      <td>(8.0, 16.0]</td>\n",
       "      <td>(-8.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>(-9.001, 56.0]</td>\n",
       "      <td>(77.0, 232.0]</td>\n",
       "      <td>(2.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6220</td>\n",
       "      <td>(81.0, 86.0]</td>\n",
       "      <td>(-9.001, 0.0]</td>\n",
       "      <td>(-8.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4651</td>\n",
       "      <td>(71.0, 74.0]</td>\n",
       "      <td>(16.0, 25.0]</td>\n",
       "      <td>(1.0, 2.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1046 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ExternalRiskEstimate NetFractionRevolvingBurden  \\\n",
       "4648         (65.0, 68.0]              (-9.001, 0.0]   \n",
       "3501         (74.0, 78.0]                 (0.0, 3.0]   \n",
       "7616         (61.0, 65.0]               (47.0, 60.0]   \n",
       "8056         (65.0, 68.0]                 (3.0, 8.0]   \n",
       "5783         (56.0, 61.0]               (36.0, 47.0]   \n",
       "...                   ...                        ...   \n",
       "2052         (56.0, 61.0]              (-9.001, 0.0]   \n",
       "2813         (81.0, 86.0]                (8.0, 16.0]   \n",
       "36         (-9.001, 56.0]              (77.0, 232.0]   \n",
       "6220         (81.0, 86.0]              (-9.001, 0.0]   \n",
       "4651         (71.0, 74.0]               (16.0, 25.0]   \n",
       "\n",
       "     NumBank2NatlTradesWHighUtilization  \n",
       "4648                     (-9.001, -8.0]  \n",
       "3501                        (-8.0, 0.0]  \n",
       "7616                         (1.0, 2.0]  \n",
       "8056                        (-8.0, 0.0]  \n",
       "5783                        (-8.0, 0.0]  \n",
       "...                                 ...  \n",
       "2052                     (-9.001, -8.0]  \n",
       "2813                        (-8.0, 0.0]  \n",
       "36                           (2.0, 3.0]  \n",
       "6220                        (-8.0, 0.0]  \n",
       "4651                         (1.0, 2.0]  \n",
       "\n",
       "[1046 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
